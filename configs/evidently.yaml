# Evidently AI Configuration
# Configuration for model monitoring and data/prediction drift detection

# =============================================
# 1. Dashboard Configuration
# =============================================
dashboard:
  # Enable or disable dashboard generation
  enabled: true
  
  # Dashboard output format
  # Options: 'html', 'json', 'cloud', 'streamlit'
  format: "html"
  
  # Output directory for HTML dashboards
  output_dir: "./reports/evidently"
  
  # Dashboard title template
  title_template: "Model Monitoring Report - {model_name} - {date}"
  
  # Dashboard styling
  style:
    # Color theme (options: 'light', 'dark', 'blue', 'green')
    theme: "light"
    
    # Company logo URL (for branding dashboards)
    logo_url: null  # e.g., "https://company.com/logo.png"
    
    # Custom CSS file path
    custom_css: null
  
  # Dashboard components to include
  components:
    # Data quality overview
    data_quality: true
    
    # Data drift section
    data_drift: true
    
    # Target drift section
    target_drift: true
    
    # Model performance section
    model_performance: true
    
    # Metrics over time section
    metrics_over_time: true
    
    # Explainability section
    explainability: false

# =============================================
# 2. Monitoring Settings
# =============================================
monitoring:
  # Monitoring service configuration
  service:
    # Enable or disable the monitoring service
    enabled: true
    
    # Service mode
    # Options: 'batch', 'online', 'hybrid'
    mode: "hybrid"
    
    # Monitoring frequency for batch mode (in hours)
    batch_frequency: 24  # Run every 24 hours
    
    # Reference data configuration
    reference_data:
      # Path to reference dataset (for drift comparison)
      path: "./data/reference_data.parquet"
      
      # Format of reference data
      format: "parquet"  # Options: 'csv', 'parquet', 'json'
      
      # How often to refresh reference data (in days)
      refresh_period: 30  # Refresh every 30 days
      
      # Whether to use initial training data as reference
      use_training_data: true
      
      # Maximum number of samples to use from reference
      max_samples: 10000
    
    # Current data configuration (for online monitoring)
    current_data:
      # Buffer size for streaming data
      buffer_size: 1000
      
      # Window size for rolling metrics
      window_size: 500
      
      # Data storage for online monitoring
      storage:
        # Type of storage
        # Options: 'memory', 'filesystem', 'database'
        type: "memory"
        
        # Filesystem path (if using filesystem storage)
        path: "./data/monitoring"
        
        # Database configuration (if using database storage)
        database:
          # Connection string
          uri: "sqlite:///data/monitoring.db"
          
          # Table name
          table: "monitoring_data"
  
  # Logging configuration
  logging:
    # Log level
    # Options: 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'
    level: "INFO"
    
    # Log to file
    file:
      # Enable file logging
      enabled: true
      
      # Log file path
      path: "./logs/evidently.log"
      
      # Maximum log file size in MB
      max_size_mb: 10
      
      # Number of backup log files to keep
      backup_count: 5
    
    # Log to console
    console:
      # Enable console logging
      enabled: true

# =============================================
# 3. Data Drift Detection Configuration
# =============================================
data_drift:
  # Enable data drift detection
  enabled: true
  
  # Features to monitor for drift
  # Leave empty to monitor all features
  features_to_monitor: []
  
  # Features to exclude from drift monitoring
  exclude_features: ["id", "timestamp"]
  
  # Statistical test settings
  statistical_tests:
    # Test for numerical features
    # Options: 'kolmogorov_smirnov', 'wasserstein', 'jensen_shannon', 'psi'
    numerical: "kolmogorov_smirnov"
    
    # Test for categorical features
    # Options: 'chi_square', 'jensen_shannon', 'psi'
    categorical: "chi_square"
    
    # Significance level (p-value) threshold for drift detection
    # Lower values make drift detection more conservative
    significance_level: 0.05
  
  # Data preprocessing for drift calculations
  preprocessing:
    # Whether to drop NaN values before calculating drift
    drop_nan: true
    
    # Whether to fill NaN values with defaults
    fill_nan: false
    
    # Default value for categorical NaN
    categorical_nan_value: "missing"
    
    # Default value for numerical NaN
    numerical_nan_value: 0
  
  # Visualization settings
  visualization:
    # Whether to generate feature distribution plots
    distribution_plots: true
    
    # Maximum number of feature plots to generate
    max_feature_plots: 20
    
    # Types of plots to generate
    # Options: 'histogram', 'kde', 'box', 'violin'
    plot_types: ["histogram", "kde"]

# =============================================
# 4. Model Performance Monitoring Configuration
# =============================================
model_performance:
  # Enable model performance monitoring
  enabled: true
  
  # Model type
  # Options: 'classification', 'regression', 'ranking'
  model_type: "classification"
  
  # Target column name
  target_column: "target"
  
  # Prediction column name
  prediction_column: "prediction"
  
  # Probability column name (for classification)
  probability_column: "probability"
  
  # Classification settings (for classification models)
  classification:
    # Classification task type
    # Options: 'binary', 'multiclass'
    task_type: "binary"
    
    # Positive class label (for binary classification)
    positive_label: 1
    
    # Whether to calculate per-class metrics
    per_class_metrics: true
    
    # Probability threshold for binary decisions
    probability_threshold: 0.5
    
    # Classification metrics to calculate
    metrics:
      - "accuracy"
      - "precision"
      - "recall"
      - "f1"
      - "roc_auc"
      - "confusion_matrix"
      - "precision_recall_curve"
  
  # Regression settings (for regression models)
  regression:
    # Regression metrics to calculate
    metrics:
      - "rmse"
      - "mae"
      - "mape"
      - "r2"
      - "max_error"
      - "residuals_plot"
    
    # Whether to use scaled metrics
    scale_metrics: true
  
  # Concept drift detection
  concept_drift:
    # Enable concept drift detection
    enabled: true
    
    # Method for concept drift detection
    # Options: 'performance_drop', 'prediction_drift', 'combined'
    method: "combined"
    
    # Significance level for concept drift
    significance_level: 0.01

# =============================================
# 5. Metric Calculation Settings
# =============================================
metrics:
  # Enable additional custom metrics
  custom_metrics: true
  
  # Calculate metrics on segments
  segmented_metrics:
    # Enable segmented metrics
    enabled: true
    
    # Columns to use for segmentation
    segment_columns: ["segment"]
    
    # Minimum segment size for metric calculation
    min_segment_size: 100
  
  # Time-based aggregation
  time_aggregation:
    # Enable time-based metric aggregation
    enabled: true
    
    # Column containing timestamps
    timestamp_column: "timestamp"
    
    # Frequency for aggregation
    # Options: 'daily', 'hourly', 'weekly', 'monthly'
    frequency: "daily"
  
  # Calculation settings
  calculation:
    # Whether to use sampling for large datasets
    use_sampling: true
    
    # Sample size if sampling is enabled
    sample_size: 10000
    
    # Number of bootstrap iterations for confidence intervals
    bootstrap_iterations: 100
    
    # Confidence level for intervals
    confidence_level: 0.95

# =============================================
# 6. Reporting and Alert Thresholds
# =============================================
reporting:
  # Report generation
  reports:
    # Generate summary report
    summary: true
    
    # Generate detailed report
    detailed: true
    
    # Include raw data in reports
    include_raw_data: false
    
    # Maximum features to include in detailed reports
    max_features_in_report: 50
  
  # Alert configuration
  alerts:
    # Enable alerting
    enabled: true
    
    # Methods for sending alerts
    methods:
      # Email alerts
      email:
        enabled: false
        recipients: []
        subject_template: "ML Monitoring Alert: {alert_type} - {model_name}"
      
      # Slack alerts
      slack:
        enabled: false
        webhook_url: ""
        channel: "#model-monitoring"
      
      # Custom webhook
      webhook:
        enabled: false
        url: ""
        headers: {}
    
    # Alert severity levels
    severity_levels:
      # Critical alerts
      critical:
        # Threshold for data drift to trigger critical alert
        data_drift_threshold: 0.7  # Proportion of drifted features
        
        # Threshold for performance drop to trigger critical alert
        performance_drop_threshold: 0.1  # Absolute drop in performance metric
      
      # Warning alerts
      warning:
        # Threshold for data drift to trigger warning
        data_drift_threshold: 0.3
        
        # Threshold for performance drop to trigger warning
        performance_drop_threshold: 0.05
  
  # Scheduled reporting
  scheduled_reports:
    # Enable scheduled reports
    enabled: true
    
    # Frequency of scheduled reports
    # Options: 'daily', 'weekly', 'monthly'
    frequency: "weekly"
    
    # Day of week for weekly reports (0 = Monday, 6 = Sunday)
    day_of_week: 0
    
    # Hour of day for report generation (24-hour format)
    hour: 6

# =============================================
# 7. Integration Settings with Other Tools
# =============================================
integrations:
  # MLflow integration
  mlflow:
    # Enable MLflow integration
    enabled: true
    
    # MLflow tracking URI
    tracking_uri: "http://localhost:5000"
    
    # Log metrics to MLflow
    log_metrics: true
    
    # Log drift reports as artifacts
    log_reports: true
    
    # Log raw data samples
    log_data_samples: false
  
  # Weights & Biases integration
  wandb:
    # Enable W&B integration
    enabled: false
    
    # W&B project name
    project: "model-monitoring"
    
    # W&B entity name
    entity: "mlops-team"
    
    # Log model predictions
    log_predictions: false
  
  # Prometheus integration for metrics
  prometheus:
    # Enable Prometheus integration
    enabled: false
    
    # Prometheus push gateway URL
    gateway_url: "localhost:9091"
    
    # Job label for metrics
    job_label: "evidently_metrics"
    
    # Push frequency in seconds
    push_frequency: 60
  
  # Database storage for metrics
  database:
    # Enable database storage
    enabled: true
    
    # Database connection string
    connection_string: "sqlite:///data/metrics.db"
    
    # Table name for metrics
    metrics_table: "model_metrics"
    
    # Table name for drift results
    drift_table: "drift_metrics"
    
    # Whether to create tables if they don't exist
    create_tables: true
  
  # Grafana integration
  grafana:
    # Enable Grafana integration
    enabled: false
    
    # Grafana URL
    url: "http://localhost:3000"
    
    # Dashboard ID
    dashboard_id: null
    
    # Whether to automatically create dashboards
    create_dashboard: true

# =============================================
# Environment Variables
# =============================================
# Environment variables to use (alternative to hardcoded values)
# environment:
#   EVIDENTLY_METRICS_DB: "postgresql://user:pass@localhost:5432/metrics"
#   EVIDENTLY_ALERT_WEBHOOK: "https://webhook.example.com/alert"

