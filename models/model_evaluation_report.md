# Model Evaluation Report

**Accuracy:** 0.8649

## Classification Report
```
               precision    recall  f1-score   support

     business       0.81      0.86      0.84        51
entertainment       0.86      0.84      0.85        38
     politics       0.92      0.79      0.85        42
        sport       0.82      0.92      0.87        51
         tech       0.95      0.90      0.92        40

     accuracy                           0.86       222
    macro avg       0.87      0.86      0.87       222
 weighted avg       0.87      0.86      0.86       222

```

## Confusion Matrix
![Confusion Matrix](confusion_matrix.png)

