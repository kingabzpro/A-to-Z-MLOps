name: Continuous Deployment

# Defines when the workflow will run
on:
  # Trigger on release creation
  release:
    types: [created, edited]
  # Trigger on push to main branch with specific path patterns
  push:
    branches: [main]
    paths:
      - 'src/models/**'
      - 'src/serving/**'
      - 'configs/mlflow.yaml'
      - 'configs/huggingface.yaml'
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

# Environment variables used across the workflow jobs
env:
  PYTHON_VERSION: "3.9"
  MODEL_NAME: "mlops-model"
  MODEL_VERSION: ${{ github.ref_name || 'latest' }}
  MLFLOW_TRACKING_URI: "http://localhost:5000"  # Adjust for your MLFLOW server

jobs:
  # First job: Build and package the model
  build-model:
    name: Build and Package Model
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Check out the repository code
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          lfs: true  # Enable Git LFS for model files
      
      # Step 2: Set up Python with the specified version
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          pip install uv
          uv pip install -r requirements-prod.txt
          
      # Step 4: Configure MLflow
      - name: Configure MLflow
        run: |
          # Create necessary directories
          mkdir -p ./mlruns
          
          # Set MLflow environment variables
          echo "MLFLOW_TRACKING_URI=${{ env.MLFLOW_TRACKING_URI }}" >> $GITHUB_ENV
          echo "MLFLOW_EXPERIMENT_NAME=deployment" >> $GITHUB_ENV
      
      # Step 5: Package the model with MLflow
      - name: Package model with MLflow
        id: package-model
        run: |
          # Build and register model with MLflow
          # Replace with your actual model building script
          python -c "
          import mlflow
          import os
          
          # This is a placeholder. In a real project, you'd run your model building code here
          # and then log the model to MLflow
          
          mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])
          mlflow.set_experiment(os.environ['MLFLOW_EXPERIMENT_NAME'])
          
          with mlflow.start_run() as run:
              # Log parameters, metrics, and model - replace with your actual model
              mlflow.log_param('model_type', 'example')
              mlflow.log_metric('accuracy', 0.95)
              
              # Log a sample model - in a real project, this would be your trained model
              import sklearn.ensemble
              from sklearn.datasets import make_classification
              
              # Create a sample model
              X, y = make_classification(n_samples=100, n_features=20, random_state=42)
              model = sklearn.ensemble.RandomForestClassifier(n_estimators=10, random_state=42)
              model.fit(X, y)
              
              # Log the model
              mlflow.sklearn.log_model(
                  model, 
                  'model',
                  registered_model_name='${{ env.MODEL_NAME }}'
              )
              
              # Get the run ID
              run_id = run.info.run_id
              print(f'::set-output name=run_id::{run_id}')
              print(f'::set-output name=model_uri::runs:/{run_id}/model')
          "
      
      # Step 6: Export the model as an artifact
      - name: Export model artifacts
        run: |
          # Create artifacts directory
          mkdir -p artifacts
          
          # Download model from MLflow
          mlflow artifacts download -d artifacts/model ${{ steps.package-model.outputs.model_uri }}
          
          # Create metadata file
          echo "model_uri: ${{ steps.package-model.outputs.model_uri }}" > artifacts/metadata.yaml
          echo "run_id: ${{ steps.package-model.outputs.run_id }}" >> artifacts/metadata.yaml
          echo "model_name: ${{ env.MODEL_NAME }}" >> artifacts/metadata.yaml
          echo "model_version: ${{ env.MODEL_VERSION }}" >> artifacts/metadata.yaml
      
      # Step 7: Upload artifacts for next job
      - name: Upload model artifacts
        uses: actions/upload-artifact@v3
        with:
          name: model-artifacts
          path: artifacts/
          retention-days: 1  # Only need these for the duration of the workflow

  # Second job: Push model to Hugging Face Hub
  push-to-huggingface:
    name: Push to Hugging Face Hub
    runs-on: ubuntu-latest
    needs: build-model
    
    steps:
      # Step 1: Check out the repository code
      - name: Checkout repository
        uses: actions/checkout@v3
      
      # Step 2: Set up Python
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      # Step 3: Download model artifacts
      - name: Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: model-artifacts
          path: artifacts/
      
      # Step 4: Install Hugging Face Hub
      - name: Install Hugging Face Hub
        run: |
          pip install huggingface_hub
      
      # Step 5: Login to Hugging Face
      - name: Login to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Logging in to Hugging Face Hub"
          python -c "
          from huggingface_hub import login
          login('$HF_TOKEN')
          "
      
      # Step 6: Push model to Hugging Face Hub
      - name: Push model to HF Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_USERNAME: ${{ secrets.HF_USERNAME || github.repository_owner }}
          HF_MODEL_ID: ${{ env.MODEL_NAME }}
        run: |
          echo "Pushing model to Hugging Face Hub"
          python -c "
          import os
          from huggingface_hub import HfApi
          
          # Upload the model
          api = HfApi()
          
          # Create or get repository
          model_id = '${{ env.HF_USERNAME }}/${{ env.HF_MODEL_ID }}'
          
          try:
              # Create repo if it doesn't exist
              api.create_repo(
                  repo_id=model_id,
                  token='${{ env.HF_TOKEN }}',
                  private=True,
                  exist_ok=True
              )
          except Exception as e:
              print(f'Repository already exists or error: {e}')
          
          # Upload model files
          api.upload_folder(
              folder_path='artifacts/model',
              repo_id=model_id,
              token='${{ env.HF_TOKEN }}'
          )
          
          # Add model card if not exists
          model_card = '''
          ---
          language: en
          license: apache-2.0
          library_name: mlflow
          tags:
            - mlops
            - mlflow
            - classification
          ---
          
          # Model: ${{ env.MODEL_NAME }}
          
          This model was automatically uploaded from the MLOps pipeline.
          
          ## Model Description
          
          - Version: ${{ env.MODEL_VERSION }}
          - Type: Classification Model
          - Built with MLflow and deployed via GitHub Actions
          
          ## Intended Use
          
          This model is intended for demonstration purposes.
          
          ## Training Data
          
          The model was trained on synthetic data.
          
          ## Performance
          
          - Accuracy: 0.95
          
          ## Limitations
          
          This is a demonstration model and should not be used in production without evaluation.
          '''
          
          # Check if README.md exists
          try:
              api.hf_hub_download(repo_id=model_id, repo_type='model', filename='README.md')
              print('README.md already exists, not overwriting')
          except:
              # Create README.md (model card)
              with open('model_card.md', 'w') as f:
                  f.write(model_card)
              
              api.upload_file(
                  path_or_fileobj='model_card.md',
                  path_in_repo='README.md',
                  repo_id=model_id,
                  token='${{ env.HF_TOKEN }}'
              )
          
          print(f'Model pushed to https://huggingface.co/{model_id}')
          "

  # Third job: Deploy model API
  deploy-api:
    name: Deploy Model API
    runs-on: ubuntu-latest
    needs: [build-model, push-to-huggingface]
    environment: ${{ github.event.inputs.environment || 'staging' }}
    
    steps:
      # Step 1: Check out the repository code
      - name: Checkout repository
        uses: actions/checkout@v3
      
      # Step 2: Set up Python
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      # Step 3: Download model artifacts
      - name: Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: model-artifacts
          path: artifacts/
      
      # Step 4: Install dependencies
      - name: Install dependencies
        run: |
          pip install uv
          uv pip install -r requirements-prod.txt
      
      # Step 5: Build Docker container for API
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      # Step 6: Login to container registry (e.g., Docker Hub or GitHub Container Registry)
      - name: Login to Container Registry
        uses: docker/login-action@v2
        with:
          # Replace with your registry details
          # For GitHub Container Registry:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
          # For Docker Hub:
          # username: ${{ secrets.DOCKERHUB_USERNAME }}
          # password: ${{ secrets.DOCKERHUB_TOKEN }}
      
      # Step 7: Build and push Docker image
      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./deploy/Dockerfile
          push: true
          tags: |
            ghcr.io/${{ github.repository_owner }}/${{ env.MODEL_NAME }}-api:${{ env.MODEL_VERSION }}
            ghcr.io/${{ github.repository_owner }}/${{ env.MODEL_NAME }}-api:latest
          build-args: |
            MODEL_PATH=artifacts/model
            MODEL_NAME=${{ env.MODEL_NAME }}
            MODEL_VERSION=${{ env.MODEL_VERSION }}
      
      # Step 8: Deploy to environment (example deployment to cloud provider)
      - name: Deploy to environment
        # This is a placeholder. Replace with your actual deployment steps, e.g.:
        # - Azure Web Apps
        # - AWS Lambda
        # - Kubernetes
        # - Custom server
        run: |
          echo "Deploying model API to ${{ github.event.inputs.environment || 'staging' }}"
          echo "This is a placeholder step - implement your actual deployment here"
          
          # Example command for a cloud deployment could be:
          # az webapp config container set --name my-app --resource-group my-group --docker-custom-image-name ghcr.io/...
          
          # For demonstration, just log success
          echo "Model API deployment successful"
      
      # Step 9: Run smoke test against deployed API
      - name: Run smoke test
        run: |
          echo "Running smoke test against deployed API"
          # This is a placeholder. Replace with your actual smoke test:
          # curl -X POST https://api.example.com/predict -d '{"data": [1, 2, 3, 4]}' -H "Content-Type: application/json"
          echo "Smoke test successful"

  # Fourth job: Update status and notify
  notify:
    name: Update Status and Notify
    runs-on: ubuntu-latest
    needs: [deploy-api]
    if: always()
    
    steps:
      # Step 1: Check out the repository code
      - name: Checkout repository
        uses: actions/checkout@v3
      
      # Step 2: Generate deployment status
      - name: Generate deployment status
        id: status
        run: |
          if [[ "${{ needs.deploy-api.result }}" == "success" ]]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "message=Model deployed successfully" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "message=Model deployment failed" >> $GITHUB_OUTPUT
          fi
      
      # Step 3: Update deployment status in GitHub
      - name: Update deployment status
        uses: bobheadxi/deployments@v1
        with:
          step: finish
          token: ${{ secrets.GITHUB_TOKEN }}
          status: ${{ steps.status.outputs.status }}
          deployment_id: ${{ github.run_id }}
          env: ${{ github.event.inputs.environment || 'staging' }}
          desc: ${{ steps.status.outputs.message }}
      
      # Step 4: Send notification (example with Slack)
      - name: Send notification
        if: always()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          SLACK_CHANNEL: mlops-deployments
          SLACK_COLOR: ${{ steps.status.outputs.status == 'success' && 'good' || 'danger' }}
          SLACK_ICON: https://github.com/rtCamp.png?size=48
          SLACK_MESSAGE: ${{ steps.status.outputs.message }}
          SLACK_TITLE: Model Deployment Status
          SLACK_USERNAME: MLOps Bot
        continue-on-error: true  # Continue even if notification fails

